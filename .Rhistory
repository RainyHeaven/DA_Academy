library(e1071)
library(tm)
Sys.setlocale(category = "LC_ALL", locale = "us")
library(tm)
setwd('C:/Users/stu/git/DA_Academy')
library(e1071)
library(tm)
raw <- read.csv('sms_spam.csv', header = T, stringsAsFactors = F)
ham <- raw[raw[,1]=='ham',]
spam <- raw[raw[,1]=='spam',]
head(ham)
?tm
raw[,2] <- Corpus(raw[,2])
raw[,2] <- Corpus(VectorSource(raw[,2]))
head(raw[,2])
raw[,2] <- Corpus(VectorSource(raw[,2]))
head(raw[,2])
ham <- raw[raw[,1]=='ham',]
spam <- raw[raw[,1]=='spam',]
hamcorp <- Corpus(VectorSource(unlist(ham)))
hamCorp <- Corpus(VectorSource(unlist(ham)))
spamCorp <- Corpus(VectorSource(unlist(spam)))
summary(hamcorp)
inspect(hamcorp)
hamCorp <- Corpus(VectorSource(unlist(ham[,2])))
spamCorp <- Corpus(VectorSource(unlist(spam[,2])))
inspect(hamcorp)
ham[,2]
hamCorp <- Corpus(VectorSource(ham[,2]))
inspect(hamCorp)
rm(list=ls())
raw <- read.csv('sms_spam.csv', header = T, stringsAsFactors = F)
ham <- raw[raw[,1]=='ham',]
spam <- raw[raw[,1]=='spam',]
hamCorp <- Corpus(VectorSource(ham[,2]))
inspect(hamCorp)
hamCorp <- Corpus(VectorSource(unlist(ham[,2])))
inspect(hamCorp)
hamCorp_1 <- Corpus(VectorSource(ham[,2]))
hamCorp_2 <- Corpus(VectorSource(unlist(ham[,2])))
hamCorp_1==hamCorp_2
setequal(hamCorp_1,hamCorp_2)
setequal(hamCorp_1,hamCorp_2)
hamCorp <- Corpus(VectorSource(ham[,2]))
spamCorp <- Corpus(VectorSource(ham[,2]))
rm(list=ls())
raw <- read.csv('sms_spam.csv', header = T, stringsAsFactors = F)
ham <- raw[raw[,1]=='ham',]
spam <- raw[raw[,1]=='spam',]
hamCorp <- Corpus(VectorSource(ham[,2]))
spamCorp <- Corpus(VectorSource(ham[,2]))
hamDoc <- TermDocumentMatrix(hamCorp, removePunctuation=T, wordLengths>=2)
hamDoc <- TermDocumentMatrix(hamCorp, wordLengths>=2)
?TermDocumentMatrix
hamDoc <- TermDocumentMatrix(hamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths>1))
hamDoc <- TermDocumentMatrix(hamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))
hamDoc <- as.matrix(TermDocumentMatrix(hamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf)))
hamDoc <- as.matrix(TermDocumentMatrix(hamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
hamDoc
inspect(hamDoc)
rowSums(hamDoc)
sort(rowSums(hamDoc), decreasing = T)
hamFreq <- sort(rowSums(hamDoc), decreasing = T)
spamDoc <- as.matrix(TermDocumentMatrix(spamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
hamFreq <- sort(rowSums(hamDoc), decreasing = T)
spamFreq <- sort(rowSums(hamDoc), decreasing = T)
hamFreq
spamFreq
names(hamFreq)
hName <- names(hamFreq)
sName <- names(spamFreq)
hamFreq[!hName%in%sName]
hamFreq[!names(hamFreq)%in%sName]
setequal(hName, sName)
hamFreq
spamFreq
spamFreq <- sort(rowSums(spamDoc), decreasing = T)
hamFreq[!names(hamFreq)%in%sName]
hName <- names(hamFreq)
sName <- names(spamFreq)
hamFreq[!names(hamFreq)%in%sName]
hamFreq <- sort(rowSums(hamDoc), decreasing = T)
spamFreq <- sort(rowSums(spamDoc), decreasing = T)
hName <- names(hamFreq)
sName <- names(spamFreq)
hamFreq[!names(hamFreq)%in%sName]
setequl(hName, sName)
seteqaul(hName, sName)
setequal(hName, sName)
rm(list=ls())
raw <- read.csv('sms_spam.csv', header = T, stringsAsFactors = F)
ham <- raw[raw[,1]=='ham',]
spam <- raw[raw[,1]=='spam',]
hamCorp <- Corpus(VectorSource(ham[,2]))
spamCorp <- Corpus(VectorSource(spam[,2]))
hamDoc <- as.matrix(TermDocumentMatrix(hamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
hamDoc <- as.matrix(TermDocumentMatrix(hamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
spamDoc <- as.matrix(TermDocumentMatrix(spamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
spamDoc <- as.matrix(TermDocumentMatrix(spamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
hamFreq <- sort(rowSums(hamDoc), decreasing = T)
hamDoc <- as.matrix(TermDocumentMatrix(hamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
spamDoc <- as.matrix(TermDocumentMatrix(spamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
hamFreq <- sort(rowSums(hamDoc), decreasing = T)
spamFreq <- sort(rowSums(spamDoc), decreasing = T)
spamFreq <- sort(rowSums(spamDoc), decreasing = T)
hName <- names(hamFreq)
spamFreq <- sort(rowSums(spamDoc), decreasing = T)
hName <- names(hamFreq)
sName <- names(spamFreq)
hamFreq[!names(hamFreq)%in%sName]
setequal(hName, sName)
hamFreq[!names(hamFreq)%in%sName]
hamOnly <- hamFreq[!names(hamFreq)%in%sName]
spamOnly <- spamFreq[!names(spamFreq)%in%hName]
hamFreq[!hName%in%sName]
hamOnly <- hamFreq[!hNamee%in%sName]
spamOnly <- spamFreq[!sName%in%hName]
hamOnly <- hamFreq[!hNamee%in%sName]
hamOnly <- hamFreq[!hName%in%sName]
spamOnly <- spamFreq[!sName%in%hName]
hamOnly
spamOnly
hamFreq
spamFreq
length(hamOnly)
length(spamOnly)
summary(hamFreq)
length(hamFreq)
length(spamFreq)
length(hamOnly)/length(hamFreq)
length(hamOnly)/length(hamFreq)*100
length(spamOnly)/length(spamFreq)*100
#
NROW(ham)
NROW(spam)
hamOnly100 <- hamFreq[!hName%in%sName][1:100]
spamOnly100 <- spamFreq[!sName%in%hName][1:100]
length(hamOnly100)
# ham/spam의 전체 단어 수
length(hamFreq[1:100]) #6788
# ham/spam 각자만 사용하는 단어 수
length(hamOnly100) #5834
length(spamOnly100) #1819
tail(hamOnly100)
hamOnly100
hamTerm <- DocumentTermMatrix(hamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf)))
spamTerm <- DocumentTermMatrix(spamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf)))
hamTerm
inspect(hamTerm)
inspect(hamTerm)
corpus <- Corpus(VectorSource(raw[,2]))
dtm <- DocumentTermMatrix(corpus, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf)))
inspect(dtm)
class(dtm)
inspect(dtm[1])
inspect(dtm[2])
inspect(dtm)
dtm
colnames(dtm)
hamDoc
hamOnly100 <- hamFreq[!hName%in%sName][1:100]
dtm_dict <- findFreqTerms(dtm, 2)
dtm_train <- DocumentTermMatrix(corpus, list(dictionary = dtm_dict))
dtm_train
inspect(dtm_train)
hamOnly100
spamOnly100
## 1 단계 :  스팸 SMS 메시지 데이터 준비
# sms 데이터 프레임으로 sms 데이터 읽기
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
# sms 데이터 구조
str(sms_raw)
# 팩터로 spam/ham으로 변환
sms_raw$type <- factor(sms_raw$type)
# 변수형 확인
str(sms_raw$type)
# 텍스트 마이닝(tm) 패키지를 사용하여 말뭉치 생성
library(tm)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
sms_corpus <- Corpus(VectorSource(sms_raw$text))
# sms 말뭉치 확인
print(sms_corpus)
inspect(sms_corpus[1:3])
# tm_map() 사용하여 말뭉치 정리
corpus_clean <- tm_map(sms_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
# 문서-용어 희소 매트릭스 생성
sms_dtm <- DocumentTermMatrix(corpus_clean)
# 훈련과 테스트 데이터셋 생성
sms_raw_train <- sms_raw[1:4169, ]
sms_raw_test  <- sms_raw[4170:5559, ]
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
sms_corpus_train <- corpus_clean[1:4169]
inspect(sms_dtm)
# 빈번한 단어에 대한 속성 지시자
findFreqTerms(sms_dtm_train, 5)
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
sms_test  <- DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
# 훈련과 테스트 데이터셋 생성
sms_raw_train <- sms_raw[1:4169, ]
sms_raw_test  <- sms_raw[4170:5559, ]
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
sms_corpus_train <- corpus_clean[1:4169]
# 훈련 데이터를 스팸과 햄으로 구분
spam <- subset(sms_raw_train, type == "spam")
ham  <- subset(sms_raw_train, type == "ham")
# 빈번한 단어에 대한 속성 지시자
findFreqTerms(sms_dtm_train, 5)
# 빈번한 단어에 대한 속성 지시자
findFreqTerms(sms_dtm_train, 5)
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
# 빈번한 단어에 대한 속성 지시자
findFreqTerms(sms_dtm_train, 5)
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
sms_test  <- DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
sms_test  <- DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
sms_corpus_test  <- corpus_clean[4170:5559]
sms_corpus_test  <- corpus_clean[4170:5559]
sms_test  <- DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
# 개수를 팩터로 변환
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
}
# apply() convert_counts()를 사용한 훈련/테스트 데이터 추출
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
# apply() convert_counts()를 사용한 훈련/테스트 데이터 추출
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_test, MARGIN = 2, convert_counts)
?apply
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
str(sms_train)
inspect(sms_train)
sms_train
class(sms_train)
mode(sms_train)
sms_train
sms_train[1]
sms_train[1,]
sms_train[2,]
sms_train[3,]
inspect(sms_train[3,])
inspect(sms_train[1,])
inspect(sms_train[,1])
inspect(sms_train[1,1])
sms_dict
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
sms_test  <- DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
# 개수를 팩터로 변환
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
}
# apply() convert_counts()를 사용한 훈련/테스트 데이터 추출
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
# apply() convert_counts()를 사용한 훈련/테스트 데이터 추출
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_test, MARGIN = 2, convert_counts)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
sms_classifier
## 3 단계 : 모델 성능 평가
sms_test_pred <- predict(sms_classifier, sms_test)
## 3 단계 : 모델 성능 평가
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE)
CrossTable(sms_test_pred, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE)
sms_test_pred
sms_test_pred[sms_test_pred=='spam']
sms_test_pred[sms_test_pred=='ham']
## 4 단계 : 모델 성능 향상 ----
sms_classifier2 <- naiveBayes(sms_train, sms_raw_train$type, laplace = 1)
## 4 단계 : 모델 성능 향상 ----
sms_classifier2 <- naiveBayes(sms_train, sms_raw_train$type, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
## 4 단계 : 모델 성능 향상 ----
sms_classifier2 <- naiveBayes(sms_train, sms_raw_train$type, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
sms_dict
corpus <- Corpus(VectorSource(raw$text))
length(corpus)
length(corpus)*0.7
ceiling(length(corpus)*0.7)
sample(1:length(corpus), ceiling(length(corpus)*0.7))
length(sample(1:length(corpus), ceiling(length(corpus)*0.7)))
trainidx <- sample(1:length(corpus), ceiling(length(corpus)*0.7))
trainIdx <- sample(1:length(corpus), ceiling(length(corpus)*0.7))
dim(corpus)
trainCorpus <- corpus[trainIdx]
trainCorpus
testCorpus <- corpus[-trainIdx]
train <- DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict))
train
train[1]
inspect(train[1])
inspect(train[1,])
inspect(train[2,])
sms_dict <- c(names(hamOnly100), names(spamOnly100))
train <- DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict))
test <- DocumentTermMatrix(testCorpus, list(dictionary = sms_dict))
spamChecker <- naiveBayes(train, raw$type[trainIdx])
class(train)
mode(train)
sms_dict <- c(names(hamOnly100), names(spamOnly100))
train <- DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict))
test <- DocumentTermMatrix(testCorpus, list(dictionary = sms_dict))
spamChecker <- naiveBayes(train, raw$type[trainIdx,])
raw$type[trainIdx]
class(raw$type[trainIdx])
spamChecker <- naiveBayes(train, raw[trainIdx,1])
raw[trainIdx,1]
class(sms_train)
spamChecker <- naiveBayes(as.matrix(train), raw[trainIdx,1])
predict(spamChecker, as.matrix(test))
raw$type <- factor(raw$type)
spamChecker <- naiveBayes(as.matrix(train), raw[trainIdx,1])
predict(spamChecker, as.matrix(test))
checked <- predict(spamChecker, as.matrix(test))
CrossTable(checked, raw[-trainIdx, 1])
spamChecker <- naiveBayes(as.matrix(train), raw[trainIdx,1], laplace = 0.1)
checked <- predict(spamChecker, as.matrix(test))
CrossTable(checked, raw[-trainIdx, 1])
CrossTable(checked, raw[-trainIdx, 1])
hamOnly100 <- hamFreq[!hName%in%sName][1:200]
spamOnly100 <- spamFreq[!sName%in%hName][1:200]
trainIdx <- sample(1:length(corpus), ceiling(length(corpus)*0.7))
trainCorpus <- corpus[trainIdx]
testCorpus <- corpus[-trainIdx]
sms_dict <- c(names(hamOnly100), names(spamOnly100))
train <- DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict))
test <- DocumentTermMatrix(testCorpus, list(dictionary = sms_dict))
spamChecker <- naiveBayes(as.matrix(train), raw[trainIdx,1], laplace = 0.1)
checked <- predict(spamChecker, as.matrix(test))
CrossTable(checked, raw[-trainIdx, 1])
hamOnly100
hamOnly100 <- hamFreq[!hName%in%sName][1:100]
spamOnly100 <- spamFreq[!sName%in%hName][1:100]
gsub(pattern = '[1-9]', replacement = 1, x = train)
train
inspect(train)
gsub(pattern = '[1-9]', replacement = 1, x = train)
train[train>0]
train[train>0, ]
as.matrix(train)
tt <- as.matrix(train)
tt[tt>0]
train <- as.matrix(DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict)))
test <- as.matrix(DocumentTermMatrix(testCorpus, list(dictionary = sms_dict)))
train[train>0] <- 1
test[test>0] <- 1
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0.1)
checked <- predict(spamChecker, test)
CrossTable(checked, raw[-trainIdx, 1])
hamOnly100 <- hamFreq[!hName%in%sName][1:1000]
spamOnly100 <- spamFreq[!sName%in%hName][1:1000]
trainIdx <- sample(1:length(corpus), ceiling(length(corpus)*0.7))
trainCorpus <- corpus[trainIdx]
testCorpus <- corpus[-trainIdx]
sms_dict <- c(names(hamOnly100), names(spamOnly100))
train <- as.matrix(DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict)))
test <- as.matrix(DocumentTermMatrix(testCorpus, list(dictionary = sms_dict)))
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0.1)
checked <- predict(spamChecker, test)
CrossTable(checked, raw[-trainIdx, 1])
head(sms_raw_train)
head(sms_dtm_train)
head(inspect(sms_dtm_train))
head(sms_corpus_train)
head(inspect(sms_corpus_train))
sms_dict <- spamOnly
train <- as.matrix(DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict)))
test <- as.matrix(DocumentTermMatrix(testCorpus, list(dictionary = sms_dict)))
spamonly
spamOnly
sms_dict <- names(spamOnly)
train <- as.matrix(DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict)))
test <- as.matrix(DocumentTermMatrix(testCorpus, list(dictionary = sms_dict)))
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0.1)
checked <- predict(spamChecker, test)
CrossTable(checked, raw[-trainIdx, 1])
trainIdx <- sample(1:length(corpus), ceiling(length(corpus)*0.7))
trainCorpus <- corpus[trainIdx]
testCorpus <- corpus[-trainIdx]
sms_dict <- names(spamOnly)
train <- as.matrix(DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict)))
test <- as.matrix(DocumentTermMatrix(testCorpus, list(dictionary = sms_dict)))
train[train>0] <- 1
test[test>0] <- 1
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0.1)
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0.1)
checked <- predict(spamChecker, test)
hamOnly100 <- hamFreq[!hName%in%sName][1:10]
spamOnly100 <- spamFreq[!sName%in%hName][1:10]
sms_dict <- c(names(hamOnly100), names(spamOnly100))
totalDoc <- as.matrix(TermDocumentMatrix(corpus, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
totalFreq <- sort(rowSums(totalDoc), decreasing = T)
hamFreq <- sort(rowSums(hamDoc), decreasing = T)
spamFreq <- sort(rowSums(spamDoc), decreasing = T)
tName <- names(totalFreq)
# 전체 단어 수
length(totalFreq)
hamOnly100 <- hamFreq[!hName%in%sName][1:1000]
spamOnly100 <- spamFreq[!sName%in%hName][1:1000]
trainIdx <- sample(1:length(corpus), ceiling(length(corpus)*0.7))
trainCorpus <- corpus[trainIdx]
testCorpus <- corpus[-trainIdx]
sms_dict <- c(names(hamOnly100), names(spamOnly100))
train <- as.matrix(DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict)))
test <- as.matrix(DocumentTermMatrix(testCorpus, list(dictionary = sms_dict)))
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0.1)
checked <- predict(spamChecker, test)
CrossTable(checked, raw[-trainIdx, 1])
sms_dict <- c(names(hamOnly), names(spamOnly))
train <- as.matrix(DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict)))
test <- as.matrix(DocumentTermMatrix(testCorpus, list(dictionary = sms_dict)))
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0.1)
checked <- predict(spamChecker, test)
CrossTable(checked, raw[-trainIdx, 1])
class(raw[-trainIdx, 1])
CrossTable(checked, raw[-trainIdx, 1])
checked
raw <- read.csv('sms_spam.csv', header = T, stringsAsFactors = F)
raw$type <- factor(raw$type)
rm(list=ls())
raw <- read.csv('sms_spam.csv', header = T, stringsAsFactors = F)
raw$type <- factor(raw$type)
corpus <- Corpus(VectorSource(raw$text))
trainIdx <- sample(1:length(corpus), ceiling(length(corpus)*0.7))
hamCorp <- Corpus(VectorSource(ham[,2]))
spamCorp <- Corpus(VectorSource(spam[,2]))
ham <- raw[raw[,1]=='ham',]
spam <- raw[raw[,1]=='spam',]
hamCorp <- Corpus(VectorSource(ham[,2]))
spamCorp <- Corpus(VectorSource(spam[,2]))
totalDoc <- as.matrix(TermDocumentMatrix(corpus, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
hamDoc <- as.matrix(TermDocumentMatrix(hamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
spamDoc <- as.matrix(TermDocumentMatrix(spamCorp, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf))))
totalFreq <- sort(rowSums(totalDoc), decreasing = T)
hamFreq <- sort(rowSums(hamDoc), decreasing = T)
spamFreq <- sort(rowSums(spamDoc), decreasing = T)
tName <- names(totalFreq)
hName <- names(hamFreq)
sName <- names(spamFreq)
hamOnly <- hamFreq[!hName%in%sName]
spamOnly <- spamFreq[!sName%in%hName]
trainIdx <- sample(1:length(corpus), ceiling(length(corpus)*0.7))
trainCorpus <- corpus[trainIdx]
testCorpus <- corpus[-trainIdx]
str(sms_dict)
sms_dict <- c(names(hamOnly), names(spamOnly))
str(sms_dict)
train <- as.matrix(DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict)))
test <- as.matrix(DocumentTermMatrix(testCorpus, list(dictionary = sms_dict)))
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0.1)
checked <- predict(spamChecker, test)
CrossTable(checked, raw[-trainIdx, 1])
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0)
checked <- predict(spamChecker, test)
CrossTable(checked, raw[-trainIdx, 1])
test
inspect(test)
test[1,]
sms_dict <- names(spamOnly)
train <- as.matrix(DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict)))
test <- as.matrix(DocumentTermMatrix(testCorpus, list(dictionary = sms_dict)))
train[train>0] <- 1
test[test>0] <- 1
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0.001)
checked <- predict(spamChecker, test)
sms_dict <- names(spamOnly)
train <- as.matrix(DocumentTermMatrix(trainCorpus, list(dictionary = sms_dict)))
test <- as.matrix(DocumentTermMatrix(testCorpus, list(dictionary = sms_dict)))
train[train>0] <- 1
test[test>0] <- 1
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 0.001)
checked <- predict(spamChecker, test)
CrossTable(checked, raw[-trainIdx, 1])
spamChecker <- naiveBayes(train, raw[trainIdx,1], laplace = 1)
checked <- predict(spamChecker, test)
CrossTable(checked, raw[-trainIdx, 1])
length(corpus)
inspect(corpus)
corpus
summary(corpus)
raw <- read.csv('sms_spam.csv', header = T, stringsAsFactors = F)
data <- raw[1:10]
data <- raw[1:10,]
corpus <- Corpus(VectorSource(raw[,2]))
dtm <- DocumentTermMatrix(corpus, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf)))
dtm
inspect(dtm)
raw <- read.csv('sms_spam.csv', header = T, stringsAsFactors = F)
data <- raw[1:10,]
corpus <- Corpus(VectorSource(data[,2]))
dtm <- DocumentTermMatrix(corpus, control=list(removePunctuation=T, stopwords=T, wordLengths=c(2,Inf)))
dtm
inspect(dtm)
