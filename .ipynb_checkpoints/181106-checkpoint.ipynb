{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[문제] xor를 logistic regression classifier를 이용해서 프로그램을 생성하세요.\n",
    "```\n",
    "000\n",
    "011\n",
    "101\n",
    "110\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.2610717\n",
      "1000 0.65117455\n",
      "2000 0.5679742\n",
      "3000 0.48415333\n",
      "4000 0.23172247\n",
      "5000 0.11469449\n",
      "6000 0.073206976\n",
      "7000 0.053081132\n",
      "8000 0.041400976\n",
      "9000 0.03383339\n",
      "10000 0.02855461\n",
      "11000 0.024672981\n",
      "12000 0.02170384\n",
      "13000 0.019362038\n",
      "14000 0.017469412\n",
      "15000 0.015909005\n",
      "16000 0.01460104\n",
      "17000 0.013489279\n",
      "18000 0.012532947\n",
      "19000 0.011701801\n",
      "20000 0.010972885\n",
      "hypothesis: [[0.00966258]\n",
      " [0.9872044 ]\n",
      " [0.9873998 ]\n",
      " [0.00858376]]\n",
      "predict: [[0.00966258]\n",
      " [0.9872044 ]\n",
      " [0.9873998 ]\n",
      " [0.00858376]]\n",
      "acuraccy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]],dtype=np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# input\n",
    "w_1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "b_1 = tf.Variable(tf.random_normal([1]), name='bias1')\n",
    "hp_1 = tf.sigmoid(tf.matmul(x, w_1)+b_1)\n",
    "\n",
    "# hidden layer\n",
    "w_2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "b_2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hp_2 = tf.sigmoid(tf.matmul(hp_1,w_2)+b_2)\n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hp_2)+(1-y)*tf.log(1-hp_2)) # cross entropy cost function\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "predict = tf.cast(hp_2 > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(20001):\n",
    "        cost_val,_ = sess.run([cost, train], feed_dict={x:x_data, y:y_data})\n",
    "        if step%1000 == 0:\n",
    "            print(step, cost_val)\n",
    "    h,c,a = sess.run([hp_2, predict, accuracy], feed_dict={x:x_data, y:y_data})\n",
    "    print(\"hypothesis:\", h)\n",
    "    print(\"predict:\", h)\n",
    "    print(\"acuraccy:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.010972885\n",
      "1000 0.010972885\n",
      "2000 0.010972885\n",
      "3000 0.010972885\n",
      "4000 0.010972885\n",
      "5000 0.010972885\n",
      "6000 0.010972885\n",
      "7000 0.010972885\n",
      "8000 0.010972885\n",
      "9000 0.010972885\n",
      "10000 0.010972885\n",
      "11000 0.010972885\n",
      "12000 0.010972885\n",
      "13000 0.010972885\n",
      "14000 0.010972885\n",
      "15000 0.010972885\n",
      "16000 0.010972885\n",
      "17000 0.010972885\n",
      "18000 0.010972885\n",
      "19000 0.010972885\n",
      "20000 0.010972885\n",
      "hypothesis: [[0.00258899]\n",
      " [0.9977431 ]\n",
      " [0.99729174]\n",
      " [0.00306805]]\n",
      "predict: [[0.00258899]\n",
      " [0.9977431 ]\n",
      " [0.99729174]\n",
      " [0.00306805]]\n",
      "acuraccy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]],dtype=np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# input\n",
    "w_1 = tf.Variable(tf.random_normal([2, 5]), name='weight1')\n",
    "b_1 = tf.Variable(tf.random_normal([5], seed=0), name='bias1')\n",
    "layer_1 = tf.sigmoid(tf.matmul(x, w_1)+b_1)\n",
    "\n",
    "# hidden layer\n",
    "w_2 = tf.Variable(tf.random_normal([5, 4]), name='weight2')\n",
    "b_2 = tf.Variable(tf.random_normal([4]), name='bias2')\n",
    "layer_2 = tf.sigmoid(tf.matmul(layer_1,w_2)+b_2)\n",
    "\n",
    "# hidden layer\n",
    "w_3 = tf.Variable(tf.random_normal([4, 4]), name='weight3')\n",
    "b_3 = tf.Variable(tf.random_normal([4]), name='bias3')\n",
    "layer_3 = tf.sigmoid(tf.matmul(layer_2,w_3)+b_3)\n",
    "\n",
    "# output layer\n",
    "w_4 = tf.Variable(tf.random_normal([4, 1]), name='weight4')\n",
    "b_4 = tf.Variable(tf.random_normal([1]), name='bias4')\n",
    "hp = tf.sigmoid(tf.matmul(layer_3,w_4)+b_4)\n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hp)+(1-y)*tf.log(1-hp)) # cross entropy cost function\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(cost)\n",
    "predict = tf.cast(hp > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict, y), dtype=tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(20001):\n",
    "    sess.run(train,feed_dict={x:x_data, y:y_data})\n",
    "    if step%1000 == 0:\n",
    "        print(step, cost_val)\n",
    "h,c,a = sess.run([hp, predict, accuracy], feed_dict={x:x_data, y:y_data})\n",
    "print(\"hypothesis:\", h)\n",
    "print(\"predict:\", h)\n",
    "print(\"acuraccy:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classification\n",
    "import tensorflow as tf\n",
    "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "w = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hp = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "\n",
    "# logistic cost function\n",
    "cost = -tf.reduce_mean(y*tf.log(hp) + (1-y)*tf.log(1-hp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "predict = tf.cast(hp > 0.5, dtype=tf.float32) # tf.cast:  조건문과 같은 역할\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict, y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.020004\n",
      "500 0.6254851\n",
      "1000 0.53849113\n",
      "1500 0.48663878\n",
      "2000 0.4443854\n",
      "2500 0.40762612\n",
      "3000 0.3752532\n",
      "3500 0.34669113\n",
      "4000 0.32147452\n",
      "4500 0.29918048\n",
      "5000 0.27942523\n",
      "5500 0.26186785\n",
      "6000 0.24621014\n",
      "6500 0.23219548\n",
      "7000 0.21960355\n",
      "7500 0.20824671\n",
      "8000 0.19796515\n",
      "8500 0.18862319\n",
      "9000 0.18010479\n",
      "9500 0.17231101\n",
      "10000 0.1651572\n",
      "hypothesis: [[0.03759236]\n",
      " [0.16720788]\n",
      " [0.33613726]\n",
      " [0.76743823]\n",
      " [0.9304502 ]\n",
      " [0.9771566 ]]\n",
      "predict: [[0.03759236]\n",
      " [0.16720788]\n",
      " [0.33613726]\n",
      " [0.76743823]\n",
      " [0.9304502 ]\n",
      " [0.9771566 ]]\n",
      "acuraccy: 1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={x:x_data,y:y_data})\n",
    "        if step%500 == 0:\n",
    "            print(step, cost_val)\n",
    "    h,c,a = sess.run([hp, predict, accuracy], feed_dict={x:x_data, y:y_data})\n",
    "    print(\"hypothesis:\", h)\n",
    "    print(\"predict:\", h)\n",
    "    print(\"acuraccy:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Loss: 5.8398986\n",
      "Acc: 0.5\n",
      "Step: 100\n",
      "Loss: 0.7051436\n",
      "Acc: 0.5\n",
      "Step: 200\n",
      "Loss: 0.60350156\n",
      "Acc: 0.625\n",
      "Step: 300\n",
      "Loss: 0.54488754\n",
      "Acc: 0.875\n",
      "Step: 400\n",
      "Loss: 0.5029661\n",
      "Acc: 1.0\n",
      "Step: 500\n",
      "Loss: 0.47010916\n",
      "Acc: 1.0\n",
      "Step: 600\n",
      "Loss: 0.44311112\n",
      "Acc: 1.0\n",
      "Step: 700\n",
      "Loss: 0.42028368\n",
      "Acc: 1.0\n",
      "Step: 800\n",
      "Loss: 0.40059984\n",
      "Acc: 1.0\n",
      "Step: 900\n",
      "Loss: 0.38337386\n",
      "Acc: 1.0\n",
      "Step: 1000\n",
      "Loss: 0.3681194\n",
      "Acc: 1.0\n",
      "Step: 1100\n",
      "Loss: 0.35447738\n",
      "Acc: 1.0\n",
      "Step: 1200\n",
      "Loss: 0.3421739\n",
      "Acc: 1.0\n",
      "Step: 1300\n",
      "Loss: 0.33099544\n",
      "Acc: 1.0\n",
      "Step: 1400\n",
      "Loss: 0.32077402\n",
      "Acc: 1.0\n",
      "Step: 1500\n",
      "Loss: 0.31137347\n",
      "Acc: 1.0\n",
      "Step: 1600\n",
      "Loss: 0.30268365\n",
      "Acc: 1.0\n",
      "Step: 1700\n",
      "Loss: 0.2946133\n",
      "Acc: 1.0\n",
      "Step: 1800\n",
      "Loss: 0.28708738\n",
      "Acc: 1.0\n",
      "Step: 1900\n",
      "Loss: 0.2800425\n",
      "Acc: 1.0\n",
      "Step: 2000\n",
      "Loss: 0.27342537\n",
      "Acc: 1.0\n",
      "[[9.9800473e-01 1.9948815e-03 3.3908634e-07]] [0]\n",
      "[[1.6775414e-04 8.4307253e-02 9.1552502e-01]] [2]\n",
      "[[1.6775414e-04 8.4307253e-02 9.1552502e-01]] [1]\n"
     ]
    }
   ],
   "source": [
    "#multi classification (softmax classifier)\n",
    "import numpy as np\n",
    "xy = np.loadtxt('data/train.txt', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, :-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 3])\n",
    "y = tf.placeholder(tf.int32, [None, 1])\n",
    "\n",
    "y_one_hot = tf.one_hot(y,3)\n",
    "y_one_hot = tf.reshape(y_one_hot, [-1,3])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([3,3]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([3]), name='bias')\n",
    "\n",
    "logits = tf.matmul(x,w) + b\n",
    "hp = tf.nn.softmax(logits)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "prediction = tf.argmax(hp, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    sess.run(train, feed_dict={x:x_data, y:y_data})\n",
    "    if step%100==0:\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x:x_data, y:y_data})\n",
    "        print('Step:', step)\n",
    "        print('Loss:', loss)\n",
    "        print('Acc:', acc)\n",
    "'''\n",
    "a1 = tf.Variable([0.1, 0.3, 0.5])\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(tf.argmax(a1)))\n",
    "print(sess.run(tf.argmin(a1)))\n",
    "sess.close()\n",
    "'''\n",
    "a = sess.run(hp, feed_dict={x:[[1,2,1]]})\n",
    "print(a, sess.run(tf.argmax(a, 1)))\n",
    "\n",
    "b = sess.run(hp, feed_dict={x:[[1,7,7]]})\n",
    "print(b, sess.run(tf.argmax(b, 1)))\n",
    "\n",
    "c = sess.run(hp, feed_dict={x:[[1,4, 5]]})\n",
    "print(b, sess.run(tf.argmax(c, 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
