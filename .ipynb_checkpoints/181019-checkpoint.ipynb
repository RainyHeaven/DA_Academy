{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 엔트로피(Entropy)\n",
    "-  정보이론(Information theory)에서 정보의 가치는 놀람의 정도(degree of surprise)에 따라 결정\n",
    "-  정보 엔트로피는 불확실성의 측정\n",
    "-  섀넌 엔트로피(밑이 2인 로그로 계산)는 모든 사건 정보량의 기대값\n",
    "\n",
    "-  ## 정보이득\n",
    "    -  $전체엔트로피 - ((설명변수1의 총갯수 / 총관측값의수) * 엔트로피(설명변수1)) - ((설명변수2의 총갯수 / 총관측값의수) * 엔트로피(설명변수2))$\n",
    "    -  모든 변수에 관한 정보이득값을 계산하고 가장 높은 정보이득값을 가진 변수를 선택\n",
    "        ```python\n",
    "        import pandas as pd\n",
    "        from pandas import DataFrame, Series\n",
    "        import numpy as np\n",
    "\n",
    "        tree = pd.read_csv(\"C:/Users/stu/git/DA_Academy/tree.csv\")\n",
    "\n",
    "        ## 습도와 테니스유무\n",
    "        ```\n",
    "        ```\n",
    "          테니스유무\t아니요\t예\n",
    "        습도\t\t\n",
    "        높음\t4\t3\n",
    "        보통\t1\t6\n",
    "        ```\n",
    "        ```python\n",
    "        # 교차표\n",
    "        pd.crosstab(tree.습도,tree.테니스유무)\n",
    "\n",
    "        # entropy 전체\n",
    "        tot = round( -(9/14) * np.log2(9/14) - (5/14) * np.log2(5/14),2 )\n",
    "        # entropy 설명변수1\n",
    "        high = round( -(3/7) * np.log2(3/7) - (4/7) * np.log2(4/7),2 )\n",
    "        # entropy 설명변수2\n",
    "        normal = round( -(6/7) * np.log2(6/7) - (1/7) * np.log2(1/7),2 )\n",
    "\n",
    "        # 정보이득값\n",
    "        inf_humid = tot - (7/14)*(high + normal)\n",
    "        inf_humid\n",
    "        ```\n",
    "        ```\n",
    "        0.1499999999999999\n",
    "        ```\n",
    "        ```python\n",
    "        ## 바람과 테니스유무\n",
    "        # 교차표\n",
    "        wind_cross = pd.crosstab(tree.습도,tree.테니스유무, margins = True)\n",
    "        wind_cross\n",
    "        ```\n",
    "        ```\n",
    "                테니스유무\t아니요\t예\tAll\n",
    "        습도\t\t\t\n",
    "        높음\t4\t3\t7\n",
    "        보통\t1\t6\t7\n",
    "        All\t5\t9\t14\n",
    "        ```\n",
    "        ```python\n",
    "        tot = round( -(5/14) * np.log2(5/14) - (9/14) * np.log2(9/14), 2)\n",
    "        strong = round( -(3/6) * np.log2(3/6) - (3/6) * np.log2(3/6), 2)\n",
    "        weak = round( -(2/8) * np.log2(2/8) - (6/8) * np.log2(6/8), 2)\n",
    "        inf_wind = tot -(7/14)*(strong + weak)\n",
    "        inf_wind \n",
    "        ```\n",
    "        ```\n",
    "        0.03499999999999992\n",
    "        ```\n",
    "        \n",
    "# 지니지수\n",
    "-  모든 변수에 대해 지니 기대값을 계산하고 최소 기대값을 가진 변수를 최적변수로 선택\n",
    "    ```\n",
    "    지니지수 \n",
    "    : $1 - Σp²$\n",
    "\n",
    "    지니기대값 \n",
    "    : $(설명변수1의 총개수/총 관측값의 수) * 지니지수(설명변수1) + (설명변수1의 총개수/총 관측값의 수) * 지니지수(설명변수2)$\n",
    "    ```\n",
    "\n",
    "- 예시\n",
    "    -  습도와 테니스유무 지니기대값\n",
    "        ```python\n",
    "        high = 1 - pow(3/7,2) - pow(4/7,2) #0.49\n",
    "        low = 1-pow(6/7,2) - pow(1/7,2) #0.24\n",
    "        ex_humid = (7/14) * 0.49 + (7/14) * 0.24 #0.37\n",
    "        ```\n",
    "    -  바람과 테니스유무 지니기대값\n",
    "        ```python\n",
    "        strong = 1 - pow(3/6,2) - pow(3/6,2)) #0.5\n",
    "        weak = 1-pow(2/8,2) - pow(6/8,2) #0.38\n",
    "        ex_humid(7/14) * 0.49 + (7/14) * 0.24 #0.44\n",
    "        ```\n",
    "    -  붓꽃 품좀 분류\n",
    "        -  붓꽃의 품종은 150종류 이상이있고 크게 3가지(setosa, versicolor, virginica)로 분류\n",
    "        -  꽃잎(peteal), 꽃받침(sepal)의 폭, 길이를 측정하여 품종을 분류해보자\n",
    "            ```python\n",
    "            iris = pd.read_csv(\"c:/data/iris.csv\")\n",
    "            x = iris.drop('Name',axis = 1)\n",
    "            y = iris['Name']\n",
    "            print(y)\n",
    "            x\n",
    "\n",
    "            from sklearn.model_selection import train_test_split as tts\n",
    "            from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "            # train, test 로 분리\n",
    "            x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2) # 20%는 test 80%는 train 로 분리\n",
    "\n",
    "            # 분류 학습모델\n",
    "            classifier = DTC()\n",
    "            classifier.fit(x_train,y_train) \n",
    "\n",
    "            # 예측\n",
    "            y_predict = classifier.predict(x_test)\n",
    "            y_predict\n",
    "\n",
    "            # 예측비교\n",
    "            from sklearn.metrics import classification_report as report\n",
    "\n",
    "            print(report(y_test,y_predict))\n",
    "            # recall : 문제가 있는 부분\n",
    "\n",
    "            classifier.score(x_train,y_train) # 학습용 데이터셋 정확도\n",
    "            classifier.score(x_test,y_test) # 검증용 데이터셋 정확도 \n",
    "\n",
    "            # 임의 test\n",
    "            x1 = [[6.3,2.7,4.9,1.8]]; y1=\"Iris-virginica\"\n",
    "            y1_predict = classifier.predict(x1)\n",
    "            y1_predict\n",
    "\n",
    "            ## 비교!!! ★\n",
    "\n",
    "            # 다르게 분류한 행 찾기\n",
    "            label = classifier.predict(iris.ix[:,:4])\n",
    "            iris[iris.ix[:,4] != se(label)]\n",
    "\n",
    "            # 다르게 어떻게 분류했는가\n",
    "            label[iris.ix[:,4] != se(label)]\n",
    "            ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
