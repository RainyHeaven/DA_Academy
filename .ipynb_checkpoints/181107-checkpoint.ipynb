{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[문제] zoo data set을 이용해서 분류프로그램을 만드세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "raw = np.loadtxt('data/zoo_data.txt', delimiter=',', usecols=range(1,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Loss: 3.0116332\n",
      "Acc: 0.26732674\n",
      "Step: 200\n",
      "Loss: 0.5561329\n",
      "Acc: 0.8712871\n",
      "Step: 400\n",
      "Loss: 0.37165993\n",
      "Acc: 0.8910891\n",
      "Step: 600\n",
      "Loss: 0.28072926\n",
      "Acc: 0.9108911\n",
      "Step: 800\n",
      "Loss: 0.22356315\n",
      "Acc: 0.9207921\n",
      "Step: 1000\n",
      "Loss: 0.18501389\n",
      "Acc: 0.95049506\n",
      "Step: 1200\n",
      "Loss: 0.15764016\n",
      "Acc: 0.980198\n",
      "Step: 1400\n",
      "Loss: 0.13729352\n",
      "Acc: 0.980198\n",
      "Step: 1600\n",
      "Loss: 0.12159792\n",
      "Acc: 0.980198\n",
      "Step: 1800\n",
      "Loss: 0.1091309\n",
      "Acc: 0.980198\n",
      "Step: 2000\n",
      "Loss: 0.09899552\n",
      "Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = raw[:, :-1]\n",
    "y_data = raw[:, [-1]]\n",
    "y_data = y_data-1\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 16])\n",
    "y = tf.placeholder(tf.int32, [None, 1])\n",
    "\n",
    "y_one_hot = tf.one_hot(y, 7)\n",
    "y_one_hot = tf.reshape(y_one_hot, [-1, 7])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([16, 7], seed=0), name='weight')\n",
    "b = tf.Variable(tf.random_normal([7], seed=0), name='bias')\n",
    "\n",
    "logits = tf.matmul(x, w) + b\n",
    "hp = tf.nn.softmax(logits)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(cost)\n",
    "prediction = tf.argmax(hp, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    sess.run(train, feed_dict={x:x_data, y:y_data})\n",
    "    if step%200==0:\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x:x_data, y:y_data})\n",
    "        print('Step:', step)\n",
    "        print('Loss:', loss)\n",
    "        print('Acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0\tLoss:2.8180179595947266\tAcc:0.2772277295589447\n",
      "Step:200\tLoss:0.37078824639320374\tAcc:0.8910890817642212\n",
      "Step:400\tLoss:0.22321279346942902\tAcc:0.9207921028137207\n",
      "Step:600\tLoss:0.15745188295841217\tAcc:0.9801980257034302\n",
      "Step:800\tLoss:0.12147974967956543\tAcc:0.9801980257034302\n",
      "Step:1000\tLoss:0.09891378879547119\tAcc:1.0\n",
      "Step:1200\tLoss:0.08347164839506149\tAcc:1.0\n",
      "Step:1400\tLoss:0.07225858420133591\tAcc:1.0\n",
      "Step:1600\tLoss:0.06375382840633392\tAcc:1.0\n",
      "Step:1800\tLoss:0.05708320438861847\tAcc:1.0\n",
      "Step:2000\tLoss:0.05171000584959984\tAcc:1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = raw[:, 0:-1]\n",
    "y_data = raw[:, [-1]]\n",
    "y_data = y_data -1 # 1-7 인 값을 0-6으로 바꿈\n",
    "\n",
    "nb_classes = 7\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 16])\n",
    "y = tf.placeholder(tf.int32, [None, 1])\n",
    "\n",
    "y_one_hot = tf.one_hot(y, nb_classes)\n",
    "y_one_hot = tf.reshape(y_one_hot, [-1, nb_classes])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([16, nb_classes], seed=0), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes], seed=0), name='bias')\n",
    "\n",
    "logits = tf.matmul(x,w)+b\n",
    "hp = tf.nn.softmax(logits)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "prediction = tf.argmax(hp, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(optimizer, feed_dict={x:x_data, y:y_data})\n",
    "    if step%200==0:\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x:x_data, y:y_data})\n",
    "        print('Step:{}\\tLoss:{}\\tAcc:{}'.format(step, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "pred = sess.run(prediction, feed_dict={x:x_data})\n",
    "for p, y in zip(pred, y_data.flatten()):\n",
    "    print('[{}] Prediction: {} True Y: {}'.format(p==int(y), p, int(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2353017e-04 9.9084842e-01 5.2784500e-03 2.8502991e-04 1.0765855e-03\n",
      "  1.2360483e-03 1.0521340e-03]] [1]\n"
     ]
    }
   ],
   "source": [
    "zoo_hp = sess.run(hp, feed_dict={x:[[0,1,1,0,1,0,0,0,1,1,0,0,2,1,0,0]]})\n",
    "print(zoo_hp, sess.run(tf.argmax(zoo_hp, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03648072 0.07951338 0.03519128 0.0330734  0.01061647 0.11018044\n",
      "  0.6949444 ]] [6]\n"
     ]
    }
   ],
   "source": [
    "zoo_hp = sess.run(hp, feed_dict={x:[[0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0]]})\n",
    "print(zoo_hp, sess.run(tf.argmax(zoo_hp, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.reshape(3,4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.reshape(3,-1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2],\n",
       "        [ 3,  4,  5]],\n",
       "\n",
       "       [[ 6,  7,  8],\n",
       "        [ 9, 10, 11]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(2,2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5]],\n",
       "\n",
       "       [[ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(2,-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[문제] bmi.csv 내용을 신경망을 이용해서 분류해 보세요.\n",
    "\n",
    "#BMI\n",
    "# BMI = 몸무게 / (키(m)*키(m))\n",
    "# 18.5 이상 25미만이면 표준\n",
    "#label : thin(저체중), normal(정상), fat(비만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>45</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145</td>\n",
       "      <td>72</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>61</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>56</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192</td>\n",
       "      <td>48</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175</td>\n",
       "      <td>77</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>127</td>\n",
       "      <td>39</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>152</td>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>184</td>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>186</td>\n",
       "      <td>41</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>188</td>\n",
       "      <td>60</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>181</td>\n",
       "      <td>43</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200</td>\n",
       "      <td>75</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>146</td>\n",
       "      <td>65</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>198</td>\n",
       "      <td>54</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>133</td>\n",
       "      <td>70</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>188</td>\n",
       "      <td>80</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>156</td>\n",
       "      <td>49</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200</td>\n",
       "      <td>63</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>182</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>139</td>\n",
       "      <td>60</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>134</td>\n",
       "      <td>57</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>123</td>\n",
       "      <td>48</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>164</td>\n",
       "      <td>65</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>136</td>\n",
       "      <td>44</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>184</td>\n",
       "      <td>68</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>187</td>\n",
       "      <td>64</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>194</td>\n",
       "      <td>71</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>189</td>\n",
       "      <td>65</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>141</td>\n",
       "      <td>56</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>178</td>\n",
       "      <td>48</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>166</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>143</td>\n",
       "      <td>56</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>158</td>\n",
       "      <td>58</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td>143</td>\n",
       "      <td>65</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19975</th>\n",
       "      <td>177</td>\n",
       "      <td>73</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19976</th>\n",
       "      <td>177</td>\n",
       "      <td>69</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>138</td>\n",
       "      <td>76</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19978</th>\n",
       "      <td>121</td>\n",
       "      <td>40</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19979</th>\n",
       "      <td>147</td>\n",
       "      <td>35</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>189</td>\n",
       "      <td>44</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>173</td>\n",
       "      <td>52</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>148</td>\n",
       "      <td>71</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>193</td>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>179</td>\n",
       "      <td>78</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>133</td>\n",
       "      <td>43</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>133</td>\n",
       "      <td>46</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>197</td>\n",
       "      <td>72</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>176</td>\n",
       "      <td>46</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>155</td>\n",
       "      <td>39</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>150</td>\n",
       "      <td>57</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>130</td>\n",
       "      <td>78</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>134</td>\n",
       "      <td>72</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>165</td>\n",
       "      <td>35</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>188</td>\n",
       "      <td>79</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>157</td>\n",
       "      <td>67</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>138</td>\n",
       "      <td>40</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>163</td>\n",
       "      <td>62</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>169</td>\n",
       "      <td>68</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>183</td>\n",
       "      <td>39</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       height  weight   label\n",
       "0         140      45  normal\n",
       "1         145      72     fat\n",
       "2         150      61     fat\n",
       "3         137      56     fat\n",
       "4         192      48    thin\n",
       "5         175      77     fat\n",
       "6         127      39  normal\n",
       "7         152      38    thin\n",
       "8         184      38    thin\n",
       "9         186      41    thin\n",
       "10        188      60    thin\n",
       "11        181      43    thin\n",
       "12        200      75  normal\n",
       "13        146      65     fat\n",
       "14        198      54    thin\n",
       "15        133      70     fat\n",
       "16        188      80  normal\n",
       "17        156      49  normal\n",
       "18        200      63    thin\n",
       "19        182      64  normal\n",
       "20        139      60     fat\n",
       "21        134      57     fat\n",
       "22        123      48     fat\n",
       "23        164      65  normal\n",
       "24        136      44  normal\n",
       "25        184      68  normal\n",
       "26        187      64    thin\n",
       "27        194      71  normal\n",
       "28        189      65    thin\n",
       "29        141      56     fat\n",
       "...       ...     ...     ...\n",
       "19970     178      48    thin\n",
       "19971     166      64  normal\n",
       "19972     143      56     fat\n",
       "19973     158      58  normal\n",
       "19974     143      65     fat\n",
       "19975     177      73  normal\n",
       "19976     177      69  normal\n",
       "19977     138      76     fat\n",
       "19978     121      40     fat\n",
       "19979     147      35    thin\n",
       "19980     189      44    thin\n",
       "19981     173      52    thin\n",
       "19982     148      71     fat\n",
       "19983     193      38    thin\n",
       "19984     179      78  normal\n",
       "19985     133      43  normal\n",
       "19986     133      46     fat\n",
       "19987     197      72  normal\n",
       "19988     176      46    thin\n",
       "19989     155      39    thin\n",
       "19990     150      57     fat\n",
       "19991     130      78     fat\n",
       "19992     134      72     fat\n",
       "19993     165      35    thin\n",
       "19994     188      79  normal\n",
       "19995     157      67     fat\n",
       "19996     138      40  normal\n",
       "19997     163      62  normal\n",
       "19998     169      68  normal\n",
       "19999     183      39    thin\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/bmi.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.label.apply(lambda x: 0 if x=='thin' else (1 if x == 'normal' else 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Loss: 131.7219\n",
      "Acc: 0.2975\n",
      "\n",
      "\n",
      "Step: 1000\n",
      "Loss: 15.646631\n",
      "Acc: 0.4239\n",
      "\n",
      "\n",
      "Step: 2000\n",
      "Loss: 13.097046\n",
      "Acc: 0.42555\n",
      "\n",
      "\n",
      "Step: 3000\n",
      "Loss: 10.691787\n",
      "Acc: 0.4266\n",
      "\n",
      "\n",
      "Step: 4000\n",
      "Loss: 8.321888\n",
      "Acc: 0.42785\n",
      "\n",
      "\n",
      "Step: 5000\n",
      "Loss: 5.9741626\n",
      "Acc: 0.42945\n",
      "\n",
      "\n",
      "Step: 6000\n",
      "Loss: 3.6659062\n",
      "Acc: 0.43335\n",
      "\n",
      "\n",
      "Step: 7000\n",
      "Loss: 1.6127468\n",
      "Acc: 0.462\n",
      "\n",
      "\n",
      "Step: 8000\n",
      "Loss: 0.96171045\n",
      "Acc: 0.83635\n",
      "\n",
      "\n",
      "Step: 9000\n",
      "Loss: 0.8709006\n",
      "Acc: 0.8019\n",
      "\n",
      "\n",
      "Step: 10000\n",
      "Loss: 0.83217245\n",
      "Acc: 0.7927\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_data = data.iloc[:,:2]\n",
    "y_data = data.iloc[:, [2]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.int32, [None, 1])\n",
    "\n",
    "y_one_hot = tf.one_hot(y, 3)\n",
    "y_one_hot = tf.reshape(y_one_hot, [-1, 3])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([2, 3], seed=0), name='weight')\n",
    "b = tf.Variable(tf.random_normal([3], seed=0), name='bias')\n",
    "\n",
    "logits = tf.matmul(x, w) + b\n",
    "hp = tf.nn.softmax(logits)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.00005).minimize(cost)\n",
    "prediction = tf.argmax(hp, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(10001):\n",
    "    sess.run(train, feed_dict={x:x_data, y:y_data})\n",
    "    if step%1000==0:\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x:x_data, y:y_data})\n",
    "        print('Step:', step)\n",
    "        print('Loss:', loss)\n",
    "        print('Acc:', acc)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Loss: 1.7164375\n",
      "Acc: 0.3766\n",
      "\n",
      "\n",
      "Step: 1000\n",
      "Loss: 1.150158\n",
      "Acc: 0.4856\n",
      "\n",
      "\n",
      "Step: 2000\n",
      "Loss: 1.0318711\n",
      "Acc: 0.51695\n",
      "\n",
      "\n",
      "Step: 3000\n",
      "Loss: 0.94449073\n",
      "Acc: 0.5374\n",
      "\n",
      "\n",
      "Step: 4000\n",
      "Loss: 0.8750239\n",
      "Acc: 0.56095\n",
      "\n",
      "\n",
      "Step: 5000\n",
      "Loss: 0.81902575\n",
      "Acc: 0.61125\n",
      "\n",
      "\n",
      "Step: 6000\n",
      "Loss: 0.77325946\n",
      "Acc: 0.70545\n",
      "\n",
      "\n",
      "Step: 7000\n",
      "Loss: 0.7353241\n",
      "Acc: 0.7527\n",
      "\n",
      "\n",
      "Step: 8000\n",
      "Loss: 0.7034453\n",
      "Acc: 0.7794\n",
      "\n",
      "\n",
      "Step: 9000\n",
      "Loss: 0.6763021\n",
      "Acc: 0.81155\n",
      "\n",
      "\n",
      "Step: 10000\n",
      "Loss: 0.65290695\n",
      "Acc: 0.8441\n",
      "\n",
      "\n",
      "Step: 11000\n",
      "Loss: 0.6325138\n",
      "Acc: 0.85835\n",
      "\n",
      "\n",
      "Step: 12000\n",
      "Loss: 0.61455256\n",
      "Acc: 0.86965\n",
      "\n",
      "\n",
      "Step: 13000\n",
      "Loss: 0.5985825\n",
      "Acc: 0.8793\n",
      "\n",
      "\n",
      "Step: 14000\n",
      "Loss: 0.58426267\n",
      "Acc: 0.88365\n",
      "\n",
      "\n",
      "Step: 15000\n",
      "Loss: 0.57132137\n",
      "Acc: 0.88665\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_data = scaler.fit_transform(data.iloc[:,:2])\n",
    "y_data = data.iloc[:, [2]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.int32, [None, 1])\n",
    "\n",
    "y_one_hot = tf.one_hot(y, 3)\n",
    "y_one_hot = tf.reshape(y_one_hot, [-1, 3])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([2, 3], seed=0), name='weight')\n",
    "b = tf.Variable(tf.random_normal([3], seed=0), name='bias')\n",
    "\n",
    "logits = tf.matmul(x, w) + b\n",
    "hp = tf.nn.softmax(logits)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.005).minimize(cost)\n",
    "prediction = tf.argmax(hp, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(15001):\n",
    "    sess.run(train, feed_dict={x:x_data, y:y_data})\n",
    "    if step%1000==0:\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x:x_data, y:y_data})\n",
    "        print('Step:', step)\n",
    "        print('Loss:', loss)\n",
    "        print('Acc:', acc)\n",
    "        print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
